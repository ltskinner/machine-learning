# Linear Algebra and Optimization for Machine Learning

[Linear Algebra and Optimization for Machine Learning](https://www.amazon.com/Linear-Algebra-Optimization-Machine-Learning/dp/3030403432)

This book goes out of its way to teach linear algebra and optimization with ML examples

The exercises within the text of the chapter should be solved as one reads the chapter in order to solidify the concepts.

The exercises at the end of the chapter are intended to be solved as refreshers after completing the chapter

Notations:

Vectors or multi-dimensional data points are $\bar{X} or \bar{y}  $ - the bar is the distinguishing feature

Vector dot products are denoted by centered dots, such as $\bar{X} \cdot \bar{Y}  $. A matrix is denoted in captial letters without a bar, like $R $.

The $n \times d $ matrix corresponding to the entire training dataset is denoted by D with n data points and d dimensions. The individual data points in D are therefore d-dimensional row vectors and are often denoted by $\bar{X}_{1} ... \bar{X}_{n}  $.

Conversely, vectors with one component for each data point are usually n-dimensional column vectors. An example is the n-dimensional column vector \bar{y} of class variables of n data points.

A observed value $y_{i}$ is distinguised from a predicted value $\hat{y_{i}}$

## [Chapter 1. Linear Algebra and Optimization: An Introduction](./CHAPTER_1.md)
