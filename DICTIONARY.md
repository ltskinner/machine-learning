# Dictionary

Random stuff with no better home

- regularization
  - A technique to prevent overfitting by adding a penalty term (like L1 or L2) to the loss function, discouraging overly complex models.
  - controls model complexity
- normalization
  - A preprocessing step to scale input features to a common range (e.g. [0, 1] or mean 0 and variance 1 aka 'standard normal' distribution)
  - improves model convergence and performance, and ensures features are on comparable scales
